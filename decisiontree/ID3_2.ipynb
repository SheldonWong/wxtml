{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataset = [[0, 0, 0, 0, 'N'], \n",
    "               [0, 0, 0, 1, 'N'], \n",
    "               [1, 0, 0, 0, 'Y'], \n",
    "               [2, 1, 0, 0, 'Y'], \n",
    "               [2, 2, 1, 0, 'Y'], \n",
    "               [2, 2, 1, 1, 'N'], \n",
    "               [1, 2, 1, 1, 'Y']]\n",
    "    labels = ['outlook', 'temperature', 'humidity', 'windy']\n",
    "    return dataset, labels\n",
    "\n",
    "\n",
    "def createDataSet2():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacing','flippers']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "['no surfacing', 'flippers']\n"
     ]
    }
   ],
   "source": [
    "dataSet,labels = createDataSet2()\n",
    "print(dataSet)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 信息熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yes': 2, 'no': 3}\n"
     ]
    }
   ],
   "source": [
    "# 无论是最初未划分前的数据，还是划分后的数据，信息熵的计算都是根据最后一列计算的\n",
    "# 具体来说，依赖于最后一列的统计量，统计最后一列{取值：个数}\n",
    "def unique(dataSet):\n",
    "    d = {}\n",
    "    column = [example[-1] for example in dataSet]\n",
    "    for v in column:\n",
    "        if(v not in d.keys()): d[v] = 0\n",
    "        d[v] += 1\n",
    "    return d\n",
    "print(unique(dataSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "# 根据类别统计计算信息熵\n",
    "from math import log\n",
    "def entropy(dataSet):\n",
    "    sample_num = len(dataSet)\n",
    "    result = 0.0\n",
    "    for k,v in unique(dataSet).items():\n",
    "        prob = v / sample_num\n",
    "        result -= prob * log(prob,2)\n",
    "    return result\n",
    "print(entropy(dataSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 选择切分数据的最佳特征（根据特征的取值，切分数据）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以第0个特征为分裂特征进行分裂数据集，\n",
      "分裂特征值为0的子集合： [[0, 1, 'no'], [0, 1, 'no']]\n",
      "分裂特征值为1的子集合： [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no']]\n",
      "分裂特征值为2的子集合： []\n"
     ]
    }
   ],
   "source": [
    "# 根据(feature_index，value)划分数据集\n",
    "\n",
    "def split_dataset(dataset, feature_index, value):\n",
    "    sub_dataset = []\n",
    "    for sample in dataset:\n",
    "        if sample[feature_index] == value:\n",
    "            sub_dataset.append(sample)\n",
    "    return sub_dataset\n",
    "\n",
    "# 返回分裂特征的索引\n",
    "print('以第0个特征为分裂特征进行分裂数据集，')\n",
    "print('分裂特征值为0的子集合：',splitDataSet(dataSet,0,0))\n",
    "print('分裂特征值为1的子集合：',splitDataSet(dataSet,0,1))\n",
    "print('分裂特征值为2的子集合：',splitDataSet(dataSet,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_index:0,info_gain:0.4199730940219749\n",
      "best_feature_index:0,best_infogain:0.4199730940219749\n",
      "feature_index:1,info_gain:0.17095059445466854\n",
      "best_feature_index:0,best_infogain:0.4199730940219749\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 维护一个未使用特征索引列表，\n",
    "# 对于未使用的特征，计算信息增益，选择最佳特征，加入到表示决策树的嵌套字典中\n",
    "# 参数1 划分后的数据集，参数2 未使用特征索引列表\n",
    "def choose_best_feature(dataset,rest_features):\n",
    "    \n",
    "    #当前节点数据集的信息熵（可能是根，也可能是叶子节点）\n",
    "    base_entropy = entropy(dataset)\n",
    "    # 信息增益\n",
    "    best_infogain = 0.0; best_feature_index = -1# 初始化   \n",
    "    \n",
    "    #对于未使用的特征，遍历计算信息增益\n",
    "    for feature_index in rest_features:\n",
    "        #当前列对应的特征取值列表\n",
    "        feature_value_list = [sample[feature_index] for sample in dataset]\n",
    "        unique_val = set(feature_value_list)\n",
    "        new_entropy = 0.0\n",
    "        \n",
    "        #计算信息增益\n",
    "        for value in unique_val:\n",
    "            #按照第feature_index的value列划分数据集\n",
    "            sub_dataset = split_dataset(dataset,feature_index,value)\n",
    "            prob = len(sub_dataset)/float(len(dataset))\n",
    "            new_entropy += prob * entropy(sub_dataset)\n",
    "       \n",
    "        info_gain = base_entropy - new_entropy        \n",
    "        \n",
    "        print('feature_index:{0},info_gain:{1}'.format(feature_index,info_gain))\n",
    "        \n",
    "        if(info_gain > best_infogain):\n",
    "            best_infogain = info_gain\n",
    "            best_feature_index = feature_index\n",
    "            \n",
    "        print('best_feature_index:{},best_infogain:{}'.format(best_feature_index,best_infogain))\n",
    "    return best_feature_index\n",
    "        \n",
    "bestFeature = choose_best_feature(dataSet,[0,1])     \n",
    "print(bestFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=0\n"
     ]
    }
   ],
   "source": [
    "a = 0 \n",
    "b = 1\n",
    "print('a={0}'.format(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 构建决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    " \n",
    "#多数表决\n",
    "def majorityCnt(classList):\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys(): classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.iteritems(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rest_labels=>[0, 1]\n",
      "feature_index:0,info_gain:0.4199730940219749\n",
      "best_feature_index:0,best_infogain:0.4199730940219749\n",
      "feature_index:1,info_gain:0.17095059445466854\n",
      "best_feature_index:0,best_infogain:0.4199730940219749\n",
      "best_feature_index=>0,rest_labels=>[1]\n",
      "best_feature_index=>0,value=>0\n",
      "best_feature_index=>0,value=>1\n",
      "rest_labels=>[1]\n",
      "feature_index:1,info_gain:0.9182958340544896\n",
      "best_feature_index:1,best_infogain:0.9182958340544896\n",
      "best_feature_index=>1,rest_labels=>[]\n",
      "best_feature_index=>1,value=>0\n",
      "best_feature_index=>1,value=>1\n",
      "{\n",
      "    \"no surfacing\": {\n",
      "        \"0\": \"no\",\n",
      "        \"1\": {\n",
      "            \"flippers\": {\n",
      "                \"0\": \"no\",\n",
      "                \"1\": \"yes\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def build_tree(dataset,rest_labels,labels):\n",
    "    class_list = [sample[-1] for sample in dataset]\n",
    "    #终止条件\n",
    "    # 类别完全相同则停止继续划分，返回类别\n",
    "    if class_list.count(class_list[0]) == len(class_list): \n",
    "        return class_list[0]\n",
    "    \n",
    "    if len(rest_labels) == 0: # 遍历完所有特征时返回出现次数最多的\n",
    "        return majorityCnt(class_list)\n",
    "    \n",
    "    print('rest_labels=>{0}'.format(rest_labels))\n",
    "    ### 选择最佳特征，划分数据集\n",
    "    best_feature_index = choose_best_feature(dataset,rest_labels)\n",
    "    best_feature_label = labels[best_feature_index]\n",
    "    myTree = {best_feature_label:{}}\n",
    "    #在特征列表中，删除指定特征索引\n",
    "    rest_labels.remove(best_feature_index)\n",
    "    print('best_feature_index=>{0},rest_labels=>{1}'.format(best_feature_index,rest_labels))\n",
    "    \n",
    "    #递归调用\n",
    "    featValues = [example[best_feature_index] for example in dataset]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        #递归调用的参数，切分后的数据集，剩余的特征，全部的labels只是为了构建树需要\n",
    "        print('best_feature_index=>{},value=>{}'.format(best_feature_index,value))\n",
    "        myTree[best_feature_label][value] = build_tree(split_dataset(dataset, best_feature_index, value),rest_labels,labels)\n",
    "    return myTree \n",
    "\n",
    "rest_labels = list(range(0,len(labels)))\n",
    "myTree= build_tree(dataSet,rest_labels,labels)\n",
    "\n",
    "import json\n",
    "print(json.dumps(myTree,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "ag=list(range(1,10))\n",
    "print(type(ag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
